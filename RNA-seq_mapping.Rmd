# (PART) Tutorials {-}
# RNA-seq mapping pipeline

Updated by Keaka Farleigh on May 15th, 2023
### ***This chapter is still under construction***

This tutorial contains code to perform quality control, mapping, and variant calling of demultiplexed samples. The dataset used in this tutorial is unpublished, but I will provide the link to the associated publication once the manuscript is published. 

This pipeline is written for paired-end (PE) sequencing data, but it has been tested with single-end (SE) sequencing data and I will note how commands can be changed to accommodate SE data. 

## Chapter ToDo for KF
 - Add workflow visualization

## Files required for this pipeline
 1. Demultiplexed RNA-seq data
 2. Genomic fasta file

## Programs used in this pipeline
 - [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) (Andrews, 2010)
 - [Trimommatic](https://github.com/usadellab/Trimmomatic) (Bolger et al., 2014)
 - [STAR](https://github.com/alexdobin/STAR) (Dobin et al., 2013)
 - [Picard](https://broadinstitute.github.io/picard/)
 - [GATK](https://gatk.broadinstitute.org/hc/en-us) (McKenna et al., 2010; but see [this website](https://gatk.broadinstitute.org/hc/en-us/articles/360035530852-How-should-I-cite-GATK-in-my-own-publications-) for additional papers published about GATK)

## Notes on this pipeline
This pipeline has been tested on Miami University's [RedHawk High Performace Computing cluster](https://miamioh.edu/research/research-computing-support/services/hpc-cluster/index.html) (HPC) and should work elsewhere, but that cannot be guaranteed. Additionally, if you are working on a cluster, please make sure you have reserved resources/are on a compute node before running this pipeline. Please [reach out](https://kfarleigh.github.io/contact/) if you would like help running this using batch jobs or if you have any questions about working in an HPC environment. 

Finally, the for loops in this pipeline are written to work with fastq, fq.gz, or bam files. In essence, the loops use the file extensions or specific character strings to create a list of files to perform some kind of action on. In most loops, the actions is to echo a command into a batch or sh file so that we can save time and do not have to do it ourselves. These loops can be adjusted easily by changing the sed command, please [reach out](https://kfarleigh.github.io/contact/) if you have any questions on how to adjust the loop. 

Let's get started and analyze some data!

## Quality control with FastQC and Trimmomatic
As with any sequencing data, the first thing that we do is quality control. We employ a two step quality control procedure. First, we use fastqc to analyze reads and manually inspect the output. Second, we use trimmomatic to perform any necessary read clipping, read filtering, or adapter removal.

Assuming that you are in your working directory with all of the demultiplexed files
``` 
# Load fastqc if you need
module load fastqc

# Run fastqc on everything in the directory
fastqc *
```

After fastqc runs, we are left with an html report for each of the files in our directory. Open a file and inspect the output, there is a lot here but we are most concerned with the Per base sequence quality graph. This graph shows us the quality scores across our reads. We expect that most of the quality scores to fall in the green area (above 28), but sometimes we see bases at the beginning or end of the read fall into the yellow (20-28) or red areas (0-20). I recommend trimming these reads to exclude anything outside of the green areas, but the decision is yours when it comes to your data. 

But how do I trim the reads or remove reads of low-quality?

We use trimmomatic to clip reads, remove low-quality reads, and exclude any adapters that are still present. I include example code below for an individual file and code to loop commands into a shell script so that you can be more efficient.

```
### Commands to trim a single individual/file
# Trimmomatic requires java
module load java
# Make a trimmed directory to keep our working directory clean
mkdir ./trimmed
# Run the trimmomatic command
java -jar /home/farleik/Software/trimmomatic-0.39.jar PE ${i}_1.fq.gz\ ${i}_2.fq.gz\ ./trimmed/${i}_1_paired.fq.gz\ ./trimmed/${i}_1_unpaired.fq.gz\ ./trimmed/${i}_2_paired.fq.gz ./trimmed/${i}_2_unpaired.fq.gz  ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36

### Loop it into a shell file for efficiency 
# This command will create a file named trimmomatic.sh in your working directory
touch trimmomatic.sh
# Trimmomatic requires java so we add the command to load java to the trimmomatic.sh file
echo module load java >> trimmomatic.sh
# We don’t want to clutter up our working directory so we need to create a directory that holds all of the output 
echo mkdir ./trimmed >> trimmomatic.sh
# The for loop to generate the trimmomatic command for each individual/file
for i in `ls -1 *_1.fq.gz | sed 's/\_1.fq.gz//'`; do echo java -jar /home/farleik/Software/trimmomatic-0.39.jar PE ${i}_1.fq.gz\ ${i}_2.fq.gz\ ./trimmed/${i}_1_paired.fq.gz\ ./trimmed/${i}_1_unpaired.fq.gz\ ./trimmed/${i}_2_paired.fq.gz ./trimmed/${i}_2_unpaired.fq.gz  ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 >> trimmomatic.sh; done
# Trim everything
sh trimmomatic.sh
```
Now that everything is trimmed we can move onto mapping with STAR

## Mapping with STAR
Mapping the RNA-seq data with STAR is relatively straightforward (only requires a couple commands), but I encourage you to familiarize yourself with the program by checking out the [manual](https://physiology.med.cornell.edu/faculty/skrabanek/lab/angsd/lecture_notes/STARmanual.pdf). The options I use here are specific for my project and while they may also be relevant to your project it is best to understand the settings you choose. 

First, we will use our genomic fasta to generate some files used by STAR during the mapping process. We then use a for loop similar to the one in the trimmomatic step to map and generate read counts for each individual. 

```
# Load STAR 
module load star-2.7.5a

# Converting GFF to GTF
./gffread Phry_platy.gff -T -o Phry_platy_ann.gtf

# Use the genome fasta to generate files used by STAR during mapping 
STAR --runMode genomeGenerate --genomeDir ./indexes/ --genomeFastaFiles ../../redo_annotation/final_assembly.fa --sjdbGTFfile ./Phry_platy_ann.GTF

# This command will create a file named trimmomatic.sh in your working directory
touch RNAseq_mapping.sh
# Trimmomatic requires java so we add the command to load java to the trimmomatic.sh file
echo module load star-2.7.5a >> RNAseq_mapping.sh

# This command is for PE data
for i in `ls -1 *_1_paired.fq.gz | sed 's/\_1_paired.fq.gz//’ `; do echo STAR --runThreadN 2 --genomeDir /shared/jezkovt_farleik_shared/Platy_RNAseq/Genome/ --readFilesIn ${i}_1_paired.fq.gz ${i}_2_paired.fq.gz --readFilesCommand zcat --limitOutSJcollapsed 2000000 --outFileNamePrefix ./${i} --outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 29000000000 --quantMode GeneCounts >> RNAseq_mapping.sh; done

sh RNAseq_mapping

# This command is for SE data, notice that there is only one input file (--readFilesIn)
for i in `ls -1 *.fastq | sed 's/\.fastq//’ `; do echo STAR --runThreadN 2 --genomeDir /shared/jezkovt_farleik_shared/Platy_RNAseq/Anolis_Data/Genome/ --readFilesIn ${i}.fastq --readFilesCommand zcat --limitOutSJcollapsed 2000000 --outFileNamePrefix ./${i} --outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 29000000000 --quantMode GeneCounts >> Anolis_IndMapping.sh; done
```

Mapping is done, well maybe. We can use the files output here to perform analyses such as differential gene expression analysis or weighted gene co-expression analysis, but if we want to call variants in our RNA-seq data I recommend following [GATK's best practices](https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels-) and using STAR's two pass method. This method increases sensitivity to novel splice junctions and in the absence of annotations it is [strongly recommended](https://github.com/alexdobin/STAR/issues/1616).


We will use the splice junction files generated by STAR (SJ.out.tab files) to re-generate our genome indices. First, we filter out potential false positive splice junctions that have very few reads, non-canonical junctions, and annotated junctions.

``` 
# I like to move all of the files to a new directory to be safe
mkdir SJ_files
mv *SJ.out.tab ./SJ_files
cd ./SJ_files
# Filter our splice junction files
cat *.tab | awk '($5 > 0 && $7 > 2 && $6==0)' | cut -f1-6 | sort | uniq > SJ_out_filtered.tab

cd ../
```

Now we can re-generate our genome indices.

```
# Generate genome indices again
STAR --genomeDir ./ --runMode genomeGenerate --genomeFastaFiles /shared/jezkovt_farleik_shared/Platy_RNAseq/Genome/GCA_020142125.1_MUOH_PhPlat_1.1_genomic.fna --sjdbGTFfile /shared/jezkovt_farleik_shared/Platy_RNAseq/Genome/*.gtf --sjdbFileChrStartEnd ./SJ_files/SJ_out_filtered.tab --runThreadN 2
``` 

Finally, we will perform the second pass mapping.

```
# Make a new directory to be tidy and not modify any of the files generated during step 1
mkdir GenomeSecondPass
mv * ./GenomeSecondPass

cd ./GenomeSecondPass

# Create the new file for 2nd pass mapping
touch Platy_IndMapping_2ndPass.sh

# Echo the STAR module into it
echo module load star-2.7.5a >> Platy_IndMapping_2ndPass.sh

# Map the reads again to the second pass genome file
 for i in `ls -1 *_1_paired.fq.gz | sed 's/\_1_paired.fq.gz//' `; do echo STAR --runThreadN 2 --genomeDir /shared/jezkovt_farleik_shared/Platy_RNAseq/SecondPass/GenomeSecondPass/  --readFilesIn ${i}_1_paired.fq.gz ${i}_2_paired.fq.gz --readFilesCommand zcat --limitOutSJcollapsed 2000000 --outFileNamePrefix ./${i}_2ndPass --outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 29000000000 --quantMode GeneCounts >> Platy_IndMapping_2ndPass.sh; done
```

2nd pass mapping is done! We can move onto variant calling with the GATK suite of tools. 

## Calling variants
Calling variants is a bit more complicated and time consuming then mapping, but it is definitely doable. Especially since we will use loops to do most of the work for us! 

### Variant calling steps
1. Add read group tags
2. Duplicate identification
3. Dictionary creation
4. Cigar splitting
5. Preliminary site calling
6. Base recalibration
7. Variant calling   

1\. We use picard to add read group tags to our reads. We add read groups tags because many programs assume that there is the presence of read group tags and will not work without them. Note, that picard will need to be downloaded from the hyperlink listed above. See the [AddorReplaceReadGroups page](https://gatk.broadinstitute.org/hc/en-us/articles/360037226472-AddOrReplaceReadGroups-Picard-) for more details. 
```
mkdir Add_Group

touch Platy_AddGroups.sh
echo module load java-20 > Platy_AddGroups.sh
for i in `ls -1 *2ndPassAligned.*.bam | sed 's/\_2ndPassAligned.sortedByCoord.out.bam//' `; do echo java -jar /home/farleik/Software/picard.jar AddOrReplaceReadGroups I= ${i}_2ndPassAligned.sortedByCoord.out.bam O= ./Add_Group/${i}_Add_Group.bam RGID=4 RGLB=lib1 RGPL=illumina RGPU=identifier RGSM=sample_name >> Platy_AddGroups.sh; done

sh Platy_AddGroups.sh

cd ./Add_Group
```

2\. We identify any duplicate reads with picard. Picard identifies duplicates by comparing the 5 prime positions of reads and then differentiates the primary read from the duplicates using the sums of the base-quality scores. Duplicate reads are labelled in the output file. See the [MarkDuplicates page](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard-) for more details. 

```
mkdir Dup_filtered

echo module load java-20 > Platy_DupFiltering.sh

for i in `ls -1 *Add_Group*.bam | sed 's/\_Add_Group.bam//' `; do echo java -jar /home/farleik/Software/picard.jar MarkDuplicates I= ${i}_Add_Group.bam O= ./Dup_filtered/${i}_DupFiltered.bam CREATE_INDEX=true VALIDATION_STRINGENCY=SILENT M= ./Dup_filtered/${i}_DupFiltered_stats.txt >> Platy_DupFiltering.sh; done

cd ./Dup_filtered
```

3\. Create a dictionary from our reference sequence with picard. The dictionary created in this step is required by many tools and will be used in subsetquent steps. See the [CreateSequenceDictionary page](https://gatk.broadinstitute.org/hc/en-us/articles/360037422891-CreateSequenceDictionary-Picard-) for more details. 

```
java -jar /home/farleik/Software/picard.jar CreateSequenceDictionary -R /shared/jezkovt_farleik_shared/Platy_RNAseq/Genome/GCA_020142125.1_MUOH_PhPlat_1.1_genomic.fna -O Platy_ref.dict
```

4\. Now we will use GATK to split Cigar N reads and reassign quality scores. This tool will split reads that contain Ns in their cigar string. For RNAseq data, these are reads that span splice events. See the [SplitNCigarReads page](https://gatk.broadinstitute.org/hc/en-us/articles/360036858811-SplitNCigarReads) for details.

```
mkdir Cigar_Split

echo module load gatk-4.1.2.0 > Platy_CigarSplit.sh

for i in `ls -1 *Dup*.bam | sed 's/\_DupFiltered.bam//' `; do echo gatk SplitNCigarReads -R Platy.fna -I ${i}_DupFiltered.bam -O ./Cigar_Split/${i}_CigarSplit.bam >> Platy_CigarSplit.sh; done

sh Platy_CigarSplit.sh
```

5\. Preliminary variant calling. We perform this step because our organism is a non-model organism and we do not know which sites are polymorphic. We need this "known sites" file so that we can perform base recalibraiton. You can skip this step if you already have a "known sites" file. This is important because the base recalibration algorithm treats mismatches as errors, but we expect variation at polymorphic sites so we use this file to skip over these sites.

```
mkdir ./Prelim_VCFcalling

echo module load gatk-4.1.2.0 > Platy_PrelimVCFcalling.sh

for i in `ls -1 *Cigar*.bam | sed 's/\_CigarSplit.bam//' `; do echo gatk HaplotypeCaller -R ../Platy.fna -I ${i}_CigarSplit.bam -O ./Prelim_VCFcalling/${i}_Prelim.g.vcf.g.gz -ERC GVCF >> Platy_PrelimVCFcalling.sh; done

sh Platy_PrelimVCFcalling.sh

cd ./Prelim_VCFcalling
# Combine the gVCFs into one multisample vcf
ls *vcf.g.gz > vcfs.list

gatk CombineGVCFs -R /shared/jezkovt_farleik_shared/Platy_RNAseq/SecondPass/Add_Group/Dup_filtered/Platy.fna --variant vcfs.list -O Prelim_Platy.g.vcf.gz
```

6\. Base recalibration. This is a really important step. Base quality scores can be thought of as per-base estimates of error calculated during sequencing. These scores can be subject to different types of error that influence base quality score estimates. The recalibration tool employs a machine learning model to adjust scores so that the over base quality scores are more accurate. See this [article](https://gatk.broadinstitute.org/hc/en-us/articles/360035890531-Base-Quality-Score-Recalibration-BQSR-) for details.

```
# Recalibrate base quality scores 
echo module load gatk-4.1.2.0 > Platy_BQSR.txt

# For loop for multiple files
for i in `ls -1 *Cigar*.bam | sed 's/\_CigarSplit.bam//' `; do echo gatkBaseRecalibrator -R ../Platy.fna -I ${i}_CigarSplit.bam -–known-sites ./Prelim_VCFcalling/Prelim_Platy.g.vcf.gz -O ${i}_recalibration.table >> Platy_BQSR.txt; done

# Apply the recalibration
mkdir ./Recalibrated_Files 

echo module load gatk-4.1.2.0 > Platy_ABQSR.txt

# Loop for multiple files 
for i in `ls -1 *Cigar*.bam | sed 's/\_CigarSplit.bam//' `; do echo gatk ApplyBQSR -R ../Platy.fna -I ${i}_CigarSplit.bam –bqsr-recal-file  ./${i}_recalibration.table -O ./Recalibrated_Files/${i}_Recalibrated.bam >> Platy_ABQSR.txt; done
```

7\. Variant calling. Finally, we get to the fun pary, variant calling. All of the data pre-processing steps have led to this and we only have a couple more to go before we have a file that is ready for analysis. This step is identical to step 5, but we use the recalibrated files from step 6 as input. See this [article](https://gatk.broadinstitute.org/hc/en-us/articles/360037225632-HaplotypeCaller) for a detailed discussion of how we call SNPs with gatk. 

```
# Make a directory for the vcf calling 
mkdir ./VCFcalling

# For Loop for the preliminary variant calling with multiple files
echo module load gatk-4.1.2.0 > Platy_VCFcalling.txt

for i in `ls -1 *Recalibrated*.bam | sed 's/\_Recalibrated.bam//' `; do echo gatk HaplotypeCaller -R ../Platy.fna -I ${i}_Recalibrated.bam -O ./VCFcalling/${i}.g.vcf.g.gz -ERC GVCF >>Platy_VCFcalling.txt; done

### Combine into a multi-sample vcf 
# List all files to combine
ls *vcf.g.gz > vcfs.list

gatk CombineGVCFs -R /shared/jezkovt_farleik_shared/Platy_RNAseq/SecondPass/Add_Group/Dup_filtered/Platy.fna --variant vcfs.list -O Platy.g.vcf.gz
```


## References
 - Andrews, S. (2010). FastQC:  A Quality Control Tool for High Throughput Sequence Data [Online]. Available online at: http://www.bioinformatics.babraham.ac.uk/projects/fastqc/
 - Bolger, A. M., Lohse, M., & Usadel, B. (2014). Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics, 30(15), 2114-2120.
 - Dobin, A., Davis, C. A., Schlesinger, F., Drenkow, J., Zaleski, C., Jha, S., ... & Gingeras, T. R. (2013). STAR: ultrafast universal RNA-seq aligner. Bioinformatics, 29(1), 15-21.
 - McKenna A, Hanna M, Banks E, Sivachenko A, Cibulskis K, Kernytsky A, Garimella K, Altshuler D, Gabriel S, Daly M, DePristo MA. (2010). The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation DNA sequencing data. Genome Res, 20:1297-303. DOI: 10.1101/gr.107524.110.